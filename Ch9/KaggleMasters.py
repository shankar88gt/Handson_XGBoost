# What Kagle Masters Do
# Exploring Competitions
# Engg New columns of Data
# Building non Corelated ensembles
# Stacking


# This page contains a curated list of examples, tutorials, blogs about XGBoost usecases - Kaggle Winning solutions
# https://github.com/dmlc/xgboost/tree/master/demo#machine-learning-challenge-winning-solutions

# More exhaustive list - if you want to research Winning solutions and learn from it
# https://www.kaggle.com/code/sudalairajkumar/winning-solutions-of-kaggle-competitions

# Light GBM Paper
# https://proceedings.neurips.cc/paper_files/paper/2017/file/6449f44a102fde848669bdd9eb6b76fa-Paper.pdf

#XGBoost Orginal Paper
#https://arxiv.org/pdf/1603.02754


# General Guidelines on Splitting the data
#   Split the data into training & a hold out set
#   Split the training set into training & test set or use cross validation
#   after obtaining a final model , test it on the hold out set.



